{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:47:18.074460Z",
     "iopub.status.busy": "2021-11-09T05:47:18.073887Z",
     "iopub.status.idle": "2021-11-09T05:47:24.395932Z",
     "shell.execute_reply": "2021-11-09T05:47:24.395221Z",
     "shell.execute_reply.started": "2021-11-09T05:47:18.074427Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "# For Transformer Models\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:47:25.887751Z",
     "iopub.status.busy": "2021-11-09T05:47:25.887269Z",
     "iopub.status.idle": "2021-11-09T05:47:30.926758Z",
     "shell.execute_reply": "2021-11-09T05:47:30.926023Z",
     "shell.execute_reply.started": "2021-11-09T05:47:25.887715Z"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"seed\": 2021,\n",
    "    \"epochs\": 3,\n",
    "    \"model_name\": \"roberta-base\",\n",
    "    \"train_batch_size\": 32,\n",
    "    \"valid_batch_size\": 64,\n",
    "    \"max_length\": 128,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"scheduler\": 'CosineAnnealingLR',\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"T_max\": 500,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"n_fold\": 5,\n",
    "    \"n_accumulate\": 1,\n",
    "    \"num_classes\": 1,\n",
    "    \"margin\": 0.5,\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}\n",
    "\n",
    "CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:47:30.928245Z",
     "iopub.status.busy": "2021-11-09T05:47:30.928003Z",
     "iopub.status.idle": "2021-11-09T05:47:30.937131Z",
     "shell.execute_reply": "2021-11-09T05:47:30.936363Z",
     "shell.execute_reply.started": "2021-11-09T05:47:30.928212Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:47:30.939248Z",
     "iopub.status.busy": "2021-11-09T05:47:30.938312Z",
     "iopub.status.idle": "2021-11-09T05:47:31.517938Z",
     "shell.execute_reply": "2021-11-09T05:47:31.517177Z",
     "shell.execute_reply.started": "2021-11-09T05:47:30.939207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  \n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2  \"Atom you don't believe actual photos of mastu...  \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4           hey \\n\\nway to support nazis, you racist  "
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/validation_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare sentence features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', '$', '&',\n",
    "          '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    "          '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›', \n",
    "          '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', \n",
    "          '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯',\n",
    "          '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔',\n",
    "          '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', '\\n', '\\r']\n",
    "\n",
    "with open('jigsaw-crawl-300d-2M.joblib', 'rb') as f:\n",
    "    crawl_emb_dict = joblib.load(f)\n",
    "\n",
    "with open('google-profanity-words/profanity.js', 'r') as handle:\n",
    "    p_words = handle.readlines()\n",
    "    \n",
    "set_puncts = set(puncts)\n",
    "\n",
    "p_word_set = set([t.replace('\\n', '') for t in p_words])\n",
    "\n",
    "def sentence_fetures(text):\n",
    "    word_list = text.split()\n",
    "    word_count = len(word_list)\n",
    "    n_upper = len([word for word in word_list if any([c.isupper() for c in word])])\n",
    "    n_unique = len(set(word_list))\n",
    "    n_ex = word_list.count('!')\n",
    "    n_que = word_list.count('?')\n",
    "    n_puncts = len([word for word in word_list if word in set_puncts])\n",
    "    n_prof = len([word for word in word_list if word in p_word_set])\n",
    "    n_oov = len([word for word in word_list if word not in crawl_emb_dict])\n",
    "    \n",
    "    return word_count, n_upper, n_unique, n_ex, n_que, n_puncts, n_prof, n_oov\n",
    "\n",
    "sentence_feature_cols = ['word_count', 'n_upper', 'n_unique', 'n_ex', 'n_que', 'n_puncts', 'n_prof', 'n_oov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30108/30108 [00:01<00:00, 29430.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>n_ex</th>\n",
       "      <th>n_que</th>\n",
       "      <th>n_puncts</th>\n",
       "      <th>n_prof</th>\n",
       "      <th>n_oov</th>\n",
       "      <th>n_upper_ratio</th>\n",
       "      <th>n_unique_ratio</th>\n",
       "      <th>n_ex_ratio</th>\n",
       "      <th>n_que_ratio</th>\n",
       "      <th>n_puncts_ratio</th>\n",
       "      <th>n_prof_ratio</th>\n",
       "      <th>n_oov_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  n_upper  n_unique  n_ex  n_que  n_puncts  n_prof  n_oov  \\\n",
       "0           6        1         5     0      0         0       0      0   \n",
       "1          39        4        38     0      0         1       0      4   \n",
       "2          16        4        15     0      0         0       0      3   \n",
       "3          27        4        26     0      0         1       0      6   \n",
       "4          22        2        20     0      0         0       2      1   \n",
       "\n",
       "   n_upper_ratio  n_unique_ratio  n_ex_ratio  n_que_ratio  n_puncts_ratio  \\\n",
       "0       0.166667        0.833333         0.0          0.0        0.000000   \n",
       "1       0.102564        0.974359         0.0          0.0        0.025641   \n",
       "2       0.250000        0.937500         0.0          0.0        0.000000   \n",
       "3       0.148148        0.962963         0.0          0.0        0.037037   \n",
       "4       0.090909        0.909091         0.0          0.0        0.000000   \n",
       "\n",
       "   n_prof_ratio  n_oov_ratio  \n",
       "0      0.000000     0.000000  \n",
       "1      0.000000     0.102564  \n",
       "2      0.000000     0.187500  \n",
       "3      0.000000     0.222222  \n",
       "4      0.090909     0.045455  "
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "feature_dict = defaultdict(list)\n",
    "\n",
    "sentence_df = {}\n",
    "\n",
    "for text in tqdm(df['less_toxic']):\n",
    "    feature_list = sentence_fetures(text)\n",
    "    for i_feature, feature_name in enumerate(sentence_feature_cols):\n",
    "        feature_dict[sentence_feature_cols[i_feature]].append(feature_list[i_feature])\n",
    "        \n",
    "sentence_df['less'] = pd.DataFrame.from_dict(feature_dict)\n",
    "\n",
    "for col in ['n_upper', 'n_unique', 'n_ex', 'n_que', 'n_puncts', 'n_prof', 'n_oov']:\n",
    "    sentence_df['less'][col + '_ratio'] = sentence_df['less'][col] / sentence_df['less']['word_count']\n",
    "    \n",
    "sentence_df['less'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df['less'].columns = [col + '_less' for col in sentence_df['less'].columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30108/30108 [00:00<00:00, 30679.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>n_ex</th>\n",
       "      <th>n_que</th>\n",
       "      <th>n_puncts</th>\n",
       "      <th>n_prof</th>\n",
       "      <th>n_oov</th>\n",
       "      <th>n_upper_ratio</th>\n",
       "      <th>n_unique_ratio</th>\n",
       "      <th>n_ex_ratio</th>\n",
       "      <th>n_que_ratio</th>\n",
       "      <th>n_puncts_ratio</th>\n",
       "      <th>n_prof_ratio</th>\n",
       "      <th>n_oov_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91</td>\n",
       "      <td>11</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.120879</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.087912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  n_upper  n_unique  n_ex  n_que  n_puncts  n_prof  n_oov  \\\n",
       "0          14       11        13     0      0         0       0      2   \n",
       "1          41       12        37     0      0         0       1      4   \n",
       "2          91       11        68     0      0         1       1      8   \n",
       "3          17        2        16     0      0         0       0      0   \n",
       "4           7        0         7     0      0         0       0      1   \n",
       "\n",
       "   n_upper_ratio  n_unique_ratio  n_ex_ratio  n_que_ratio  n_puncts_ratio  \\\n",
       "0       0.785714        0.928571         0.0          0.0        0.000000   \n",
       "1       0.292683        0.902439         0.0          0.0        0.000000   \n",
       "2       0.120879        0.747253         0.0          0.0        0.010989   \n",
       "3       0.117647        0.941176         0.0          0.0        0.000000   \n",
       "4       0.000000        1.000000         0.0          0.0        0.000000   \n",
       "\n",
       "   n_prof_ratio  n_oov_ratio  \n",
       "0      0.000000     0.142857  \n",
       "1      0.024390     0.097561  \n",
       "2      0.010989     0.087912  \n",
       "3      0.000000     0.000000  \n",
       "4      0.000000     0.142857  "
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict = defaultdict(list)\n",
    "\n",
    "for text in tqdm(df['more_toxic']):\n",
    "    feature_list = sentence_fetures(text)\n",
    "    for i_feature, feature_name in enumerate(sentence_feature_cols):\n",
    "        feature_dict[sentence_feature_cols[i_feature]].append(feature_list[i_feature])\n",
    "        \n",
    "sentence_df['more'] = pd.DataFrame.from_dict(feature_dict)\n",
    "\n",
    "for col in ['n_upper', 'n_unique', 'n_ex', 'n_que', 'n_puncts', 'n_prof', 'n_oov']:\n",
    "    sentence_df['more'][col + '_ratio'] = sentence_df['more'][col] / sentence_df['more']['word_count']\n",
    "    \n",
    "sentence_df['more'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df['more'].columns = [col + '_more' for col in sentence_df['more'].columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.concat([df, sentence_df['less'], sentence_df['more']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>word_count_less</th>\n",
       "      <th>n_upper_less</th>\n",
       "      <th>n_unique_less</th>\n",
       "      <th>n_ex_less</th>\n",
       "      <th>n_que_less</th>\n",
       "      <th>n_puncts_less</th>\n",
       "      <th>n_prof_less</th>\n",
       "      <th>...</th>\n",
       "      <th>n_puncts_more</th>\n",
       "      <th>n_prof_more</th>\n",
       "      <th>n_oov_more</th>\n",
       "      <th>n_upper_ratio_more</th>\n",
       "      <th>n_unique_ratio_more</th>\n",
       "      <th>n_ex_ratio_more</th>\n",
       "      <th>n_que_ratio_more</th>\n",
       "      <th>n_puncts_ratio_more</th>\n",
       "      <th>n_prof_ratio_more</th>\n",
       "      <th>n_oov_ratio_more</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.120879</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.087912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   worker                                         less_toxic  \\\n",
       "0     313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1     188  \"And yes, people should recognize that but the...   \n",
       "2      82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3     347  And you removed it! You numbskull! I don't car...   \n",
       "4     539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "\n",
       "                                          more_toxic  word_count_less  \\\n",
       "0  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...                6   \n",
       "1   Daphne Guinness \\n\\nTop of the mornin' my fav...               39   \n",
       "2  \"Atom you don't believe actual photos of mastu...               16   \n",
       "3  You seem to have sand in your vagina.\\n\\nMight...               27   \n",
       "4           hey \\n\\nway to support nazis, you racist               22   \n",
       "\n",
       "   n_upper_less  n_unique_less  n_ex_less  n_que_less  n_puncts_less  \\\n",
       "0             1              5          0           0              0   \n",
       "1             4             38          0           0              1   \n",
       "2             4             15          0           0              0   \n",
       "3             4             26          0           0              1   \n",
       "4             2             20          0           0              0   \n",
       "\n",
       "   n_prof_less  ...  n_puncts_more  n_prof_more  n_oov_more  \\\n",
       "0            0  ...              0            0           2   \n",
       "1            0  ...              0            1           4   \n",
       "2            0  ...              1            1           8   \n",
       "3            0  ...              0            0           0   \n",
       "4            2  ...              0            0           1   \n",
       "\n",
       "   n_upper_ratio_more  n_unique_ratio_more  n_ex_ratio_more  n_que_ratio_more  \\\n",
       "0            0.785714             0.928571              0.0               0.0   \n",
       "1            0.292683             0.902439              0.0               0.0   \n",
       "2            0.120879             0.747253              0.0               0.0   \n",
       "3            0.117647             0.941176              0.0               0.0   \n",
       "4            0.000000             1.000000              0.0               0.0   \n",
       "\n",
       "   n_puncts_ratio_more  n_prof_ratio_more  n_oov_ratio_more  \n",
       "0             0.000000           0.000000          0.142857  \n",
       "1             0.000000           0.024390          0.097561  \n",
       "2             0.010989           0.010989          0.087912  \n",
       "3             0.000000           0.000000          0.000000  \n",
       "4             0.000000           0.000000          0.142857  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/rudd_sample_all_diffs_w_sampling.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345270, 6)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 345270/345270 [00:05<00:00, 66605.67it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>n_ex</th>\n",
       "      <th>n_que</th>\n",
       "      <th>n_puncts</th>\n",
       "      <th>n_prof</th>\n",
       "      <th>n_oov</th>\n",
       "      <th>n_upper_ratio</th>\n",
       "      <th>n_unique_ratio</th>\n",
       "      <th>n_ex_ratio</th>\n",
       "      <th>n_que_ratio</th>\n",
       "      <th>n_puncts_ratio</th>\n",
       "      <th>n_prof_ratio</th>\n",
       "      <th>n_oov_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  n_upper  n_unique  n_ex  n_que  n_puncts  n_prof  n_oov  \\\n",
       "0          13        3        12     0      0         0       0      1   \n",
       "1           9        1         9     0      0         0       0      1   \n",
       "2          14        1        14     0      0         0       0      1   \n",
       "3           8        2         8     0      0         0       0      0   \n",
       "4           8        2         8     0      0         0       0      2   \n",
       "\n",
       "   n_upper_ratio  n_unique_ratio  n_ex_ratio  n_que_ratio  n_puncts_ratio  \\\n",
       "0       0.230769        0.923077         0.0          0.0             0.0   \n",
       "1       0.111111        1.000000         0.0          0.0             0.0   \n",
       "2       0.071429        1.000000         0.0          0.0             0.0   \n",
       "3       0.250000        1.000000         0.0          0.0             0.0   \n",
       "4       0.250000        1.000000         0.0          0.0             0.0   \n",
       "\n",
       "   n_prof_ratio  n_oov_ratio  \n",
       "0           0.0     0.076923  \n",
       "1           0.0     0.111111  \n",
       "2           0.0     0.071429  \n",
       "3           0.0     0.000000  \n",
       "4           0.0     0.250000  "
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "feature_dict = defaultdict(list)\n",
    "\n",
    "sentence_df = {}\n",
    "\n",
    "for text in tqdm(df['less_toxic']):\n",
    "    feature_list = sentence_fetures(text)\n",
    "    for i_feature, feature_name in enumerate(sentence_feature_cols):\n",
    "        feature_dict[sentence_feature_cols[i_feature]].append(feature_list[i_feature])\n",
    "        \n",
    "sentence_df['less'] = pd.DataFrame.from_dict(feature_dict)\n",
    "\n",
    "for col in ['n_upper', 'n_unique', 'n_ex', 'n_que', 'n_puncts', 'n_prof', 'n_oov']:\n",
    "    sentence_df['less'][col + '_ratio'] = sentence_df['less'][col] / sentence_df['less']['word_count']\n",
    "    \n",
    "sentence_df['less'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['word_count', 'n_upper', 'n_unique', 'n_ex', 'n_que', 'n_puncts',\n",
       "       'n_prof', 'n_oov', 'n_upper_ratio', 'n_unique_ratio', 'n_ex_ratio',\n",
       "       'n_que_ratio', 'n_puncts_ratio', 'n_prof_ratio', 'n_oov_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df['less'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df['less'].columns = [col + '_less' for col in sentence_df['less'].columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 345270/345270 [00:05<00:00, 65184.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>n_ex</th>\n",
       "      <th>n_que</th>\n",
       "      <th>n_puncts</th>\n",
       "      <th>n_prof</th>\n",
       "      <th>n_oov</th>\n",
       "      <th>n_upper_ratio</th>\n",
       "      <th>n_unique_ratio</th>\n",
       "      <th>n_ex_ratio</th>\n",
       "      <th>n_que_ratio</th>\n",
       "      <th>n_puncts_ratio</th>\n",
       "      <th>n_prof_ratio</th>\n",
       "      <th>n_oov_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  n_upper  n_unique  n_ex  n_que  n_puncts  n_prof  n_oov  \\\n",
       "0          12        2        12     0      0         0       0      1   \n",
       "1           8        2         8     0      0         0       0      0   \n",
       "2           4        2         4     0      0         0       0      1   \n",
       "3          24        2        22     0      0         0       0      3   \n",
       "4          11        1         9     0      0         0       0      0   \n",
       "\n",
       "   n_upper_ratio  n_unique_ratio  n_ex_ratio  n_que_ratio  n_puncts_ratio  \\\n",
       "0       0.166667        1.000000         0.0          0.0             0.0   \n",
       "1       0.250000        1.000000         0.0          0.0             0.0   \n",
       "2       0.500000        1.000000         0.0          0.0             0.0   \n",
       "3       0.083333        0.916667         0.0          0.0             0.0   \n",
       "4       0.090909        0.818182         0.0          0.0             0.0   \n",
       "\n",
       "   n_prof_ratio  n_oov_ratio  \n",
       "0           0.0     0.083333  \n",
       "1           0.0     0.000000  \n",
       "2           0.0     0.250000  \n",
       "3           0.0     0.125000  \n",
       "4           0.0     0.000000  "
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dict = defaultdict(list)\n",
    "\n",
    "for text in tqdm(df['more_toxic']):\n",
    "    feature_list = sentence_fetures(text)\n",
    "    for i_feature, feature_name in enumerate(sentence_feature_cols):\n",
    "        feature_dict[sentence_feature_cols[i_feature]].append(feature_list[i_feature])\n",
    "        \n",
    "sentence_df['more'] = pd.DataFrame.from_dict(feature_dict)\n",
    "\n",
    "for col in ['n_upper', 'n_unique', 'n_ex', 'n_que', 'n_puncts', 'n_prof', 'n_oov']:\n",
    "    sentence_df['more'][col + '_ratio'] = sentence_df['more'][col] / sentence_df['more']['word_count']\n",
    "    \n",
    "sentence_df['more'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df['more'].columns = [col + '_more' for col in sentence_df['more'].columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, sentence_df['less'], sentence_df['more']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:47:31.519549Z",
     "iopub.status.busy": "2021-11-09T05:47:31.519060Z",
     "iopub.status.idle": "2021-11-09T05:47:31.567281Z",
     "shell.execute_reply": "2021-11-09T05:47:31.566545Z",
     "shell.execute_reply.started": "2021-11-09T05:47:31.519510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>bin1</th>\n",
       "      <th>bin2</th>\n",
       "      <th>bins</th>\n",
       "      <th>score</th>\n",
       "      <th>word_count_less</th>\n",
       "      <th>n_upper_less</th>\n",
       "      <th>n_unique_less</th>\n",
       "      <th>n_ex_less</th>\n",
       "      <th>...</th>\n",
       "      <th>n_prof_more</th>\n",
       "      <th>n_oov_more</th>\n",
       "      <th>n_upper_ratio_more</th>\n",
       "      <th>n_unique_ratio_more</th>\n",
       "      <th>n_ex_ratio_more</th>\n",
       "      <th>n_que_ratio_more</th>\n",
       "      <th>n_puncts_ratio_more</th>\n",
       "      <th>n_prof_ratio_more</th>\n",
       "      <th>n_oov_ratio_more</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You go man! I wish I could spend all day with ...</td>\n",
       "      <td>Distance made it difficult long with other con...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0.122</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can you give us some examples of the food?</td>\n",
       "      <td>This has JUST the right amount of points</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Love it bro, i actually think that this is bet...</td>\n",
       "      <td>Same happened to r/VaccinesCause</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So so awesome. Really want to see more.</td>\n",
       "      <td>Every time I load a page, switch to game and t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0.271</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanks and good luck! You can do it!!</td>\n",
       "      <td>He was too good at it and realized it too late.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          less_toxic  \\\n",
       "0  You go man! I wish I could spend all day with ...   \n",
       "1         Can you give us some examples of the food?   \n",
       "2  Love it bro, i actually think that this is bet...   \n",
       "3           So so awesome. Really want to see more.    \n",
       "4              Thanks and good luck! You can do it!!   \n",
       "\n",
       "                                          more_toxic  bin1  bin2 bins  score  \\\n",
       "0  Distance made it difficult long with other con...     0     0  0-0  0.122   \n",
       "1           This has JUST the right amount of points     0     0  0-0  0.042   \n",
       "2                   Same happened to r/VaccinesCause     0     0  0-0  0.030   \n",
       "3  Every time I load a page, switch to game and t...     0     0  0-0  0.271   \n",
       "4    He was too good at it and realized it too late.     0     0  0-0  0.135   \n",
       "\n",
       "   word_count_less  n_upper_less  n_unique_less  n_ex_less  ...  n_prof_more  \\\n",
       "0               13             3             12          0  ...            0   \n",
       "1                9             1              9          0  ...            0   \n",
       "2               14             1             14          0  ...            0   \n",
       "3                8             2              8          0  ...            0   \n",
       "4                8             2              8          0  ...            0   \n",
       "\n",
       "   n_oov_more  n_upper_ratio_more  n_unique_ratio_more  n_ex_ratio_more  \\\n",
       "0           1            0.166667             1.000000              0.0   \n",
       "1           0            0.250000             1.000000              0.0   \n",
       "2           1            0.500000             1.000000              0.0   \n",
       "3           3            0.083333             0.916667              0.0   \n",
       "4           0            0.090909             0.818182              0.0   \n",
       "\n",
       "   n_que_ratio_more  n_puncts_ratio_more  n_prof_ratio_more  n_oov_ratio_more  \\\n",
       "0               0.0                  0.0                0.0          0.083333   \n",
       "1               0.0                  0.0                0.0          0.000000   \n",
       "2               0.0                  0.0                0.0          0.250000   \n",
       "3               0.0                  0.0                0.0          0.125000   \n",
       "4               0.0                  0.0                0.0          0.000000   \n",
       "\n",
       "   kfold  \n",
       "0      1  \n",
       "1      0  \n",
       "2      2  \n",
       "3      0  \n",
       "4      3  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=CONFIG['n_fold'], shuffle=True, random_state=CONFIG['seed'])\n",
    "\n",
    "for fold, ( _, val_) in enumerate(skf.split(X=df, y=df.bins)):\n",
    "    df.loc[val_ , \"kfold\"] = int(fold)\n",
    "    \n",
    "df[\"kfold\"] = df[\"kfold\"].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_FEATURE_USED = [\n",
    "    'word_count', 'n_upper', 'n_unique', 'n_ex', 'n_que', 'n_puncts',\n",
    "    'n_prof', 'n_oov', 'n_upper_ratio', 'n_unique_ratio', 'n_ex_ratio',\n",
    "    'n_que_ratio', 'n_puncts_ratio', 'n_prof_ratio', 'n_oov_ratio'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:47:31.568756Z",
     "iopub.status.busy": "2021-11-09T05:47:31.568453Z",
     "iopub.status.idle": "2021-11-09T05:47:31.579362Z",
     "shell.execute_reply": "2021-11-09T05:47:31.578390Z",
     "shell.execute_reply.started": "2021-11-09T05:47:31.568720Z"
    }
   },
   "outputs": [],
   "source": [
    "class JigsawDataset(Dataset):\n",
    "    def __init__(self, df, data, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.more_toxic = df['more_toxic'].values\n",
    "        self.less_toxic = df['less_toxic'].values\n",
    "        self.less_data = data[:, :len(SENTENCE_FEATURE_USED)]\n",
    "        self.more_data = data[:, len(SENTENCE_FEATURE_USED):]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        more_toxic = self.more_toxic[index]\n",
    "        less_toxic = self.less_toxic[index]\n",
    "        \n",
    "        less_data = self.less_data[index]\n",
    "        more_data = self.more_data[index]\n",
    "        \n",
    "        inputs_more_toxic = self.tokenizer.encode_plus(\n",
    "                                more_toxic,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        inputs_less_toxic = self.tokenizer.encode_plus(\n",
    "                                less_toxic,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        target = 1\n",
    "        \n",
    "        more_toxic_ids = inputs_more_toxic['input_ids']\n",
    "        more_toxic_mask = inputs_more_toxic['attention_mask']\n",
    "        \n",
    "        less_toxic_ids = inputs_less_toxic['input_ids']\n",
    "        less_toxic_mask = inputs_less_toxic['attention_mask']\n",
    "        \n",
    "        \n",
    "        return {\n",
    "            'more_toxic_ids': torch.tensor(more_toxic_ids, dtype=torch.long),\n",
    "            'more_toxic_mask': torch.tensor(more_toxic_mask, dtype=torch.long),\n",
    "            'more_toxic_data': torch.tensor(more_data, dtype=torch.float),\n",
    "            'less_toxic_ids': torch.tensor(less_toxic_ids, dtype=torch.long),\n",
    "            'less_toxic_mask': torch.tensor(less_toxic_mask, dtype=torch.long),\n",
    "            'less_toxic_data': torch.tensor(less_data, dtype=torch.float),\n",
    "            'target': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, RobertaModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "OUT_DROPOUT = 0.3\n",
    "BERT_N_LAST_LAYER = 4\n",
    "BERT_HIDDEN_SIZE = 768\n",
    "\n",
    "BERT_MODEL_PATH = 'roberta-base'\n",
    "BERT_DO_LOWER = 'uncased' in BERT_MODEL_PATH\n",
    "\n",
    "MAX_LEN = 220\n",
    "\n",
    "class JigsawModel(nn.Module):\n",
    "    def __init__(self, num_aux_targets, num_sentence_features):\n",
    "        super(JigsawModel, self).__init__()\n",
    "        self.bert_model = RobertaModel.from_pretrained(BERT_MODEL_PATH)\n",
    "        self.dropout = nn.Dropout(OUT_DROPOUT)\n",
    "        \n",
    "        self.linear_sentence1 = nn.Linear(num_sentence_features, num_sentence_features)\n",
    "        \n",
    "        n_hidden = BERT_HIDDEN_SIZE + num_sentence_features\n",
    "        self.linear1 = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        self.linear_out = nn.Linear(n_hidden, 1)\n",
    "        self.linear_aux_out = nn.Linear(n_hidden, num_aux_targets)\n",
    "        \n",
    "    def forward(self, ids, attention, sentence_features):\n",
    "        \n",
    "        bert_output = self.bert_model(ids, attention)[1]\n",
    "        \n",
    "        bert_output = self.dropout(bert_output)\n",
    "        \n",
    "        h_sentence = self.linear_sentence1(sentence_features)\n",
    "        \n",
    "        h_cat = torch.cat((bert_output, h_sentence), 1)\n",
    "        \n",
    "        h_conc_linear1  = F.relu(self.linear1(h_cat))\n",
    "        \n",
    "        hidden = h_cat + h_conc_linear1\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:47:31.594186Z",
     "iopub.status.busy": "2021-11-09T05:47:31.593376Z",
     "iopub.status.idle": "2021-11-09T05:47:31.605110Z",
     "shell.execute_reply": "2021-11-09T05:47:31.604507Z",
     "shell.execute_reply.started": "2021-11-09T05:47:31.594149Z"
    }
   },
   "outputs": [],
   "source": [
    "def criterion(outputs1, outputs2, targets):\n",
    "    return nn.MarginRankingLoss(margin=CONFIG['margin'])(outputs1, outputs2, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:47:31.607522Z",
     "iopub.status.busy": "2021-11-09T05:47:31.607298Z",
     "iopub.status.idle": "2021-11-09T05:47:31.618363Z",
     "shell.execute_reply": "2021-11-09T05:47:31.617555Z",
     "shell.execute_reply.started": "2021-11-09T05:47:31.607499Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "        more_toxic_ids = data['more_toxic_ids'].to(device, dtype = torch.long)\n",
    "        more_toxic_mask = data['more_toxic_mask'].to(device, dtype = torch.long)\n",
    "        more_toxic_data = data['more_toxic_data'].to(device)\n",
    "        less_toxic_ids = data['less_toxic_ids'].to(device, dtype = torch.long)\n",
    "        less_toxic_mask = data['less_toxic_mask'].to(device, dtype = torch.long)\n",
    "        less_toxic_data = data['less_toxic_data'].to(device)\n",
    "        targets = data['target'].to(device, dtype=torch.long)\n",
    "        \n",
    "        batch_size = more_toxic_ids.size(0)\n",
    "\n",
    "        more_toxic_outputs = model(more_toxic_ids, more_toxic_mask, more_toxic_data)\n",
    "        less_toxic_outputs = model(less_toxic_ids, less_toxic_mask, less_toxic_data)\n",
    "        \n",
    "        loss = criterion(\n",
    "            more_toxic_outputs, less_toxic_outputs, \n",
    "            torch.ones_like(less_toxic_outputs).to(CONFIG['device'])\n",
    "        )\n",
    "        loss = loss / CONFIG['n_accumulate']\n",
    "        loss.backward()\n",
    "    \n",
    "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
    "            optimizer.step()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n",
    "                        LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:47:31.620070Z",
     "iopub.status.busy": "2021-11-09T05:47:31.619490Z",
     "iopub.status.idle": "2021-11-09T05:47:31.631561Z",
     "shell.execute_reply": "2021-11-09T05:47:31.630872Z",
     "shell.execute_reply.started": "2021-11-09T05:47:31.620035Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    all_more = []\n",
    "    all_less = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:        \n",
    "        more_toxic_ids = data['more_toxic_ids'].to(device, dtype = torch.long)\n",
    "        more_toxic_mask = data['more_toxic_mask'].to(device, dtype = torch.long)\n",
    "        more_toxic_data = data['more_toxic_data'].to(device)\n",
    "        less_toxic_ids = data['less_toxic_ids'].to(device, dtype = torch.long)\n",
    "        less_toxic_mask = data['less_toxic_mask'].to(device, dtype = torch.long)\n",
    "        less_toxic_data = data['less_toxic_data'].to(device)\n",
    "        targets = data['target'].to(device, dtype=torch.long)\n",
    "        \n",
    "        batch_size = more_toxic_ids.size(0)\n",
    "\n",
    "        more_toxic_outputs = model(more_toxic_ids, more_toxic_mask, more_toxic_data)\n",
    "        less_toxic_outputs = model(less_toxic_ids, less_toxic_mask, less_toxic_data)\n",
    "        \n",
    "        all_more += [more_toxic_outputs.detach().cpu().numpy()]\n",
    "        all_less += [less_toxic_outputs.detach().cpu().numpy()]\n",
    "        \n",
    "        try:\n",
    "            epoch_loss = (np.hstack(all_more) > np.hstack(all_less)).mean()\n",
    "            prev_epoch_loss = epoch_loss\n",
    "        except:\n",
    "            epoch_loss = prev_epoch_loss\n",
    "        \n",
    "        bar.set_postfix(\n",
    "            Epoch=epoch, Valid_Loss=epoch_loss,\n",
    "            LR=optimizer.param_groups[0]['lr']\n",
    "        )\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:47:31.635177Z",
     "iopub.status.busy": "2021-11-09T05:47:31.634766Z",
     "iopub.status.idle": "2021-11-09T05:47:31.648350Z",
     "shell.execute_reply": "2021-11-09T05:47:31.647519Z",
     "shell.execute_reply.started": "2021-11-09T05:47:31.635139Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs, fold):\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_loss = 0\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CONFIG['device'], epoch=epoch)\n",
    "        \n",
    "        val_epoch_loss = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n",
    "                                         epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "\n",
    "        # deep copy the model\n",
    "        if val_epoch_loss > best_epoch_loss:\n",
    "            print(f\"Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n",
    "            best_epoch_loss = val_epoch_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"Loss-Fold-{fold}_roberta_base_exp.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved\")\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:47:31.649875Z",
     "iopub.status.busy": "2021-11-09T05:47:31.649524Z",
     "iopub.status.idle": "2021-11-09T05:47:31.659691Z",
     "shell.execute_reply": "2021-11-09T05:47:31.658992Z",
     "shell.execute_reply.started": "2021-11-09T05:47:31.649835Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "def prepare_loaders(fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = valid_df.reset_index(drop=True)\n",
    "    \n",
    "    sc = joblib.load(\n",
    "        '/home/anton/Documents/kaggle/jigsaw/Jigsaw-Unintended-Bias/models/fine-tune-roberta/scaler-seed0-fold0.joblib'\n",
    "    )\n",
    "    less_features = [s+'_less' for s in SENTENCE_FEATURE_USED]\n",
    "    more_features = [s+'_more' for s in SENTENCE_FEATURE_USED]\n",
    "    \n",
    "    data_train = np.hstack([\n",
    "        sc.transform(df_train[less_features].values),\n",
    "        sc.transform(df_train[more_features].values)\n",
    "    ])\n",
    "    \n",
    "    data_valid = np.hstack([\n",
    "        sc.transform(df_valid[less_features].values),\n",
    "        sc.transform(df_valid[more_features].values)\n",
    "    ])\n",
    "    \n",
    "    train_dataset = JigsawDataset(\n",
    "        df_train, data_train, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length']\n",
    "    )\n",
    "    valid_dataset = JigsawDataset(\n",
    "        df_valid, data_valid, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length']\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=16, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                              num_workers=16, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T05:47:31.661360Z",
     "iopub.status.busy": "2021-11-09T05:47:31.661095Z",
     "iopub.status.idle": "2021-11-09T05:47:31.671599Z",
     "shell.execute_reply": "2021-11-09T05:47:31.670857Z",
     "shell.execute_reply.started": "2021-11-09T05:47:31.661313Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n",
    "                                                             eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using GPU: NVIDIA RTX A5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8631/8631 [40:27<00:00,  3.56it/s, Epoch=1, LR=4.04e-6, Train_Loss=0.0496]\n",
      "100%|██████████| 471/471 [01:12<00:00,  6.48it/s, Epoch=1, LR=4.04e-6, Valid_Loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss Improved (0 ---> 0.6925626899696049)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8631/8631 [40:38<00:00,  3.54it/s, Epoch=2, LR=9.78e-6, Train_Loss=0.0203]\n",
      "100%|██████████| 471/471 [01:12<00:00,  6.45it/s, Epoch=2, LR=9.78e-6, Valid_Loss=0.693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss Improved (0.6925626899696049 ---> 0.6932038373860182)\n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8631/8631 [40:43<00:00,  3.53it/s, Epoch=3, LR=1.79e-5, Train_Loss=0.0158]\n",
      "100%|██████████| 471/471 [01:12<00:00,  6.46it/s, Epoch=3, LR=1.79e-5, Valid_Loss=0.689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete in 2h 5m 39s\n",
      "Best Loss: 0.6932\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader = prepare_loaders(fold)\n",
    "\n",
    "model = JigsawModel(6, 15)\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        '/home/anton/Documents/kaggle/jigsaw/Jigsaw-Unintended-Bias/models/fine-tune-roberta/seed0-fold0-epoch0.torchModelState'\n",
    "    )\n",
    ")\n",
    "model.to(CONFIG['device'])\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(), lr=CONFIG['learning_rate'], \n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "scheduler = fetch_scheduler(optimizer)\n",
    "\n",
    "model, history = run_training(\n",
    "    model, optimizer, scheduler,\n",
    "    device=CONFIG['device'],\n",
    "    num_epochs=CONFIG['epochs'],\n",
    "    fold=fold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on validation pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def _valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    all_more = []\n",
    "    all_less = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:        \n",
    "        more_toxic_ids = data['more_toxic_ids'].to(device, dtype = torch.long)\n",
    "        more_toxic_mask = data['more_toxic_mask'].to(device, dtype = torch.long)\n",
    "        more_toxic_data = data['more_toxic_data'].to(device)\n",
    "        less_toxic_ids = data['less_toxic_ids'].to(device, dtype = torch.long)\n",
    "        less_toxic_mask = data['less_toxic_mask'].to(device, dtype = torch.long)\n",
    "        less_toxic_data = data['less_toxic_data'].to(device)\n",
    "        targets = data['target'].to(device, dtype=torch.long)\n",
    "        \n",
    "        batch_size = more_toxic_ids.size(0)\n",
    "\n",
    "        more_toxic_outputs = model(more_toxic_ids, more_toxic_mask, more_toxic_data)\n",
    "        less_toxic_outputs = model(less_toxic_ids, less_toxic_mask, less_toxic_data)\n",
    "        \n",
    "        all_more += [more_toxic_outputs.detach().cpu().numpy()]\n",
    "        all_less += [less_toxic_outputs.detach().cpu().numpy()]\n",
    "        \n",
    "        try:\n",
    "            epoch_loss = (np.hstack(all_more) > np.hstack(all_less)).mean()\n",
    "            prev_epoch_loss = epoch_loss\n",
    "        except:\n",
    "            epoch_loss = prev_epoch_loss\n",
    "        \n",
    "        bar.set_postfix(\n",
    "            Epoch=epoch, Valid_Loss=epoch_loss\n",
    "        )\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return all_more, all_less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = JigsawModel(6, 15)\n",
    "# model.load_state_dict(\n",
    "#     torch.load(\n",
    "#         f\"Loss-Fold-4_roberta_large.bin\"\n",
    "#     )\n",
    "# )\n",
    "# model.to(CONFIG['device']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, valid_loader = prepare_loaders(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 471/471 [01:11<00:00,  6.63it/s, Epoch=0, Valid_Loss=0.693]\n"
     ]
    }
   ],
   "source": [
    "out_more, out_less = _valid_one_epoch(model, valid_loader, CONFIG['device'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_more = np.concatenate(out_more)\n",
    "out_less = np.concatenate(out_less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df['preds_less'] = out_less[:, 0]\n",
    "valid_df['preds_more'] = out_more[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6938355254417431"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(valid_df['preds_less'] < valid_df['preds_more']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique pairs validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_df = valid_df[['less_toxic', 'preds_less']]\n",
    "less_df.columns = ['txt', 'pred']\n",
    "\n",
    "more_df = valid_df[['more_toxic', 'preds_more']]\n",
    "more_df.columns = ['txt', 'pred']\n",
    "\n",
    "pred_df = pd.concat([less_df, more_df], axis=0).drop_duplicates()\n",
    "pred_df = pred_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = valid_df[['less_toxic', 'more_toxic']].copy()\n",
    "\n",
    "pairs['t1'] = pairs.apply(\n",
    "    lambda x: np.sort([x['less_toxic'], x['more_toxic']])[0], axis=1\n",
    ")\n",
    "pairs['t2'] = pairs.apply(\n",
    "    lambda x: np.sort([x['less_toxic'], x['more_toxic']])[1], axis=1\n",
    ")\n",
    "\n",
    "pairs['true'] = 0\n",
    "pairs.loc[pairs['t2'] == pairs['more_toxic'], 'true'] = 1\n",
    "\n",
    "base = pairs.groupby(['t1','t2'])['true'].mean().reset_index(name='target')\n",
    "base['target'] = base['target'].apply(lambda x: -1 if x>=0.5 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(\n",
    "    base, \n",
    "    pred_df.rename(columns={'txt': 't1', 'pred': 'pred_more'}).drop_duplicates(), \n",
    "    on='t1', how='left'\n",
    ")\n",
    "\n",
    "merged = pd.merge(\n",
    "    merged, \n",
    "    pred_df.rename(columns={'txt': 't2', 'pred': 'pred_less'}).drop_duplicates(), \n",
    "    on='t2', how='left'\n",
    ")\n",
    "\n",
    "merged['score'] = np.where(merged['pred_less'] < merged['pred_more'], 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7400039393342525"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(merged['score'] == merged['target']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10154, 6)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged[\n",
    "    (merged['score'] == merged['target'])\n",
    "    & (merged['pred_less'] < 10)\n",
    "     ]['pred_less'].hist(bins=100)\n",
    "merged[merged['score'] != merged['target']]['pred_less'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged[\n",
    "    (merged['score'] == merged['target'])\n",
    "    & (merged['pred_more'] < 10)\n",
    "     ]['pred_more'].hist(bins=100)\n",
    "\n",
    "merged[\n",
    "    (merged['score'] != merged['target'])\n",
    "    & (merged['pred_more'] < 10)\n",
    "]['pred_more'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['diff'] = merged['pred_more'] - merged['pred_less']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged['diff'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged[\n",
    "    (merged['score'] != merged['target'])\n",
    "]['diff'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged[\n",
    "    (merged['score'] == merged['target'])\n",
    "]['diff'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged[\n",
    "    (merged['score'] == merged['target'])\n",
    "]['diff'].hist(bins=100)\n",
    "\n",
    "merged[\n",
    "    (merged['score'] != merged['target'])\n",
    "]['diff'].hist(bins=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
