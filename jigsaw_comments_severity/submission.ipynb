{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:11:54.283861Z",
     "iopub.status.busy": "2022-02-06T14:11:54.283100Z",
     "iopub.status.idle": "2022-02-06T14:12:01.748811Z",
     "shell.execute_reply": "2022-02-06T14:12:01.748231Z",
     "shell.execute_reply.started": "2022-02-04T10:22:21.777107Z"
    },
    "papermill": {
     "duration": 7.492016,
     "end_time": "2022-02-06T14:12:01.748969",
     "exception": false,
     "start_time": "2022-02-06T14:11:54.256953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Utils\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "# For Transformer Models\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:12:01.829536Z",
     "iopub.status.busy": "2022-02-06T14:12:01.828829Z",
     "iopub.status.idle": "2022-02-06T14:12:01.996372Z",
     "shell.execute_reply": "2022-02-06T14:12:01.996827Z",
     "shell.execute_reply.started": "2022-02-04T10:22:28.974676Z"
    },
    "papermill": {
     "duration": 0.233503,
     "end_time": "2022-02-06T14:12:01.996989",
     "exception": false,
     "start_time": "2022-02-06T14:12:01.763486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"seed\": 2021,\n",
    "    \"epochs\": 3,\n",
    "    \"model_name\": \"../input/roberta-base\",\n",
    "    \"valid_batch_size\": 16,\n",
    "    \"max_length\": 128,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"scheduler\": 'CosineAnnealingLR',\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"T_max\": 500,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"n_fold\": 5,\n",
    "    \"n_accumulate\": 1,\n",
    "    \"num_classes\": 1,\n",
    "    \"margin\": 0.5,\n",
    "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}\n",
    "\n",
    "CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:12:02.029011Z",
     "iopub.status.busy": "2022-02-06T14:12:02.028358Z",
     "iopub.status.idle": "2022-02-06T14:12:02.033144Z",
     "shell.execute_reply": "2022-02-06T14:12:02.032739Z",
     "shell.execute_reply.started": "2022-02-04T10:22:29.185842Z"
    },
    "papermill": {
     "duration": 0.02257,
     "end_time": "2022-02-06T14:12:02.033250",
     "exception": false,
     "start_time": "2022-02-06T14:12:02.010680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:12:02.060541Z",
     "iopub.status.busy": "2022-02-06T14:12:02.059751Z",
     "iopub.status.idle": "2022-02-06T14:12:02.155376Z",
     "shell.execute_reply": "2022-02-06T14:12:02.155834Z",
     "shell.execute_reply.started": "2022-02-04T10:22:33.74016Z"
    },
    "papermill": {
     "duration": 0.110487,
     "end_time": "2022-02-06T14:12:02.155983",
     "exception": false,
     "start_time": "2022-02-06T14:12:02.045496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>\"\\n \\n\\nGjalexei, you asked about whether ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>Looks like be have an abuser , can you please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>I confess to having complete (and apparently b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>\"\\n\\nFreud's ideas are certainly much discusse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>It is not just you. This is a laundry list of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id                                               text\n",
       "0      114890  \"\\n \\n\\nGjalexei, you asked about whether ther...\n",
       "1      732895  Looks like be have an abuser , can you please ...\n",
       "2     1139051  I confess to having complete (and apparently b...\n",
       "3     1434512  \"\\n\\nFreud's ideas are certainly much discusse...\n",
       "4     2084821  It is not just you. This is a laundry list of ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:12:02.191169Z",
     "iopub.status.busy": "2022-02-06T14:12:02.190629Z",
     "iopub.status.idle": "2022-02-06T14:14:49.834216Z",
     "shell.execute_reply": "2022-02-06T14:14:49.833620Z",
     "shell.execute_reply.started": "2022-02-04T10:22:35.020927Z"
    },
    "papermill": {
     "duration": 167.665383,
     "end_time": "2022-02-06T14:14:49.834370",
     "exception": false,
     "start_time": "2022-02-06T14:12:02.168987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', '$', '&',\n",
    "          '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    "          '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›', \n",
    "          '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', \n",
    "          '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯',\n",
    "          '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔',\n",
    "          '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', '\\n', '\\r']\n",
    "\n",
    "with open('../input/reducing-oov-of-crawl300d2m-no-appos-result/jigsaw-crawl-300d-2M.joblib', 'rb') as f:\n",
    "    crawl_emb_dict = joblib.load(f)\n",
    "\n",
    "with open('../input/googleprofanitywords/google-profanity-words/profanity.js', 'r') as handle:\n",
    "    p_words = handle.readlines()\n",
    "    \n",
    "set_puncts = set(puncts)\n",
    "\n",
    "p_word_set = set([t.replace('\\n', '') for t in p_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:14:49.867665Z",
     "iopub.status.busy": "2022-02-06T14:14:49.866848Z",
     "iopub.status.idle": "2022-02-06T14:14:49.868801Z",
     "shell.execute_reply": "2022-02-06T14:14:49.869181Z",
     "shell.execute_reply.started": "2022-02-04T10:25:49.101498Z"
    },
    "papermill": {
     "duration": 0.021762,
     "end_time": "2022-02-06T14:14:49.869305",
     "exception": false,
     "start_time": "2022-02-06T14:14:49.847543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentence_fetures(text):\n",
    "    word_list = text.split()\n",
    "    word_count = len(word_list)\n",
    "    n_upper = len([word for word in word_list if any([c.isupper() for c in word])])\n",
    "    n_unique = len(set(word_list))\n",
    "    n_ex = word_list.count('!')\n",
    "    n_que = word_list.count('?')\n",
    "    n_puncts = len([word for word in word_list if word in set_puncts])\n",
    "    n_prof = len([word for word in word_list if word in p_word_set])\n",
    "    n_oov = len([word for word in word_list if word not in crawl_emb_dict])\n",
    "\n",
    "    return word_count, n_upper, n_unique, n_ex, n_que, n_puncts, n_prof, n_oov\n",
    "\n",
    "sentence_feature_cols = ['word_count', 'n_upper', 'n_unique', 'n_ex', 'n_que', 'n_puncts', 'n_prof', 'n_oov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:14:49.903760Z",
     "iopub.status.busy": "2022-02-06T14:14:49.902590Z",
     "iopub.status.idle": "2022-02-06T14:14:50.570408Z",
     "shell.execute_reply": "2022-02-06T14:14:50.570864Z",
     "shell.execute_reply.started": "2022-02-04T10:25:49.110551Z"
    },
    "papermill": {
     "duration": 0.689171,
     "end_time": "2022-02-06T14:14:50.571030",
     "exception": false,
     "start_time": "2022-02-06T14:14:49.881859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7537/7537 [00:00<00:00, 12163.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>n_upper</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>n_ex</th>\n",
       "      <th>n_que</th>\n",
       "      <th>n_puncts</th>\n",
       "      <th>n_prof</th>\n",
       "      <th>n_oov</th>\n",
       "      <th>n_upper_ratio</th>\n",
       "      <th>n_unique_ratio</th>\n",
       "      <th>n_ex_ratio</th>\n",
       "      <th>n_que_ratio</th>\n",
       "      <th>n_puncts_ratio</th>\n",
       "      <th>n_prof_ratio</th>\n",
       "      <th>n_oov_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.085470</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.118421</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>284</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.672535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  n_upper  n_unique  n_ex  n_que  n_puncts  n_prof  n_oov  \\\n",
       "0         117       10        93     0      0         2       0      9   \n",
       "1          14        1        14     0      0         1       0      1   \n",
       "2          76        9        62     0      0         0       0      7   \n",
       "3         284       40       191     0      0         3       0     26   \n",
       "4          26        3        24     0      0         0       0      1   \n",
       "\n",
       "   n_upper_ratio  n_unique_ratio  n_ex_ratio  n_que_ratio  n_puncts_ratio  \\\n",
       "0       0.085470        0.794872         0.0          0.0        0.017094   \n",
       "1       0.071429        1.000000         0.0          0.0        0.071429   \n",
       "2       0.118421        0.815789         0.0          0.0        0.000000   \n",
       "3       0.140845        0.672535         0.0          0.0        0.010563   \n",
       "4       0.115385        0.923077         0.0          0.0        0.000000   \n",
       "\n",
       "   n_prof_ratio  n_oov_ratio  \n",
       "0           0.0     0.076923  \n",
       "1           0.0     0.071429  \n",
       "2           0.0     0.092105  \n",
       "3           0.0     0.091549  \n",
       "4           0.0     0.038462  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "feature_dict = defaultdict(list)\n",
    "\n",
    "for text in tqdm(df['text']):\n",
    "    feature_list = sentence_fetures(text)\n",
    "    for i_feature, feature_name in enumerate(sentence_feature_cols):\n",
    "        feature_dict[sentence_feature_cols[i_feature]].append(feature_list[i_feature])\n",
    "        \n",
    "sentence_df = pd.DataFrame.from_dict(feature_dict)\n",
    "\n",
    "for col in ['n_upper', 'n_unique', 'n_ex', 'n_que', 'n_puncts', 'n_prof', 'n_oov']:\n",
    "    sentence_df[col + '_ratio'] = sentence_df[col] / sentence_df['word_count']\n",
    "    \n",
    "sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:14:51.467210Z",
     "iopub.status.busy": "2022-02-06T14:14:51.466483Z",
     "iopub.status.idle": "2022-02-06T14:14:51.469430Z",
     "shell.execute_reply": "2022-02-06T14:14:51.469860Z",
     "shell.execute_reply.started": "2022-02-04T10:25:49.788332Z"
    },
    "papermill": {
     "duration": 0.883262,
     "end_time": "2022-02-06T14:14:51.470005",
     "exception": false,
     "start_time": "2022-02-06T14:14:50.586743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del crawl_emb_dict, feature_dict\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:14:51.504762Z",
     "iopub.status.busy": "2022-02-06T14:14:51.504014Z",
     "iopub.status.idle": "2022-02-06T14:14:51.508154Z",
     "shell.execute_reply": "2022-02-06T14:14:51.508516Z",
     "shell.execute_reply.started": "2022-02-04T10:25:50.668958Z"
    },
    "papermill": {
     "duration": 0.022756,
     "end_time": "2022-02-06T14:14:51.508667",
     "exception": false,
     "start_time": "2022-02-06T14:14:51.485911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SENTENCE_FEATURE_USED = [\n",
    "    'word_count', 'n_upper', 'n_unique', 'n_ex', 'n_que', 'n_puncts',\n",
    "    'n_prof', 'n_oov', 'n_upper_ratio', 'n_unique_ratio', 'n_ex_ratio',\n",
    "    'n_que_ratio', 'n_puncts_ratio', 'n_prof_ratio', 'n_oov_ratio'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:14:51.547817Z",
     "iopub.status.busy": "2022-02-06T14:14:51.547087Z",
     "iopub.status.idle": "2022-02-06T14:14:51.549417Z",
     "shell.execute_reply": "2022-02-06T14:14:51.548915Z",
     "shell.execute_reply.started": "2022-02-04T10:25:50.679336Z"
    },
    "papermill": {
     "duration": 0.025216,
     "end_time": "2022-02-06T14:14:51.549518",
     "exception": false,
     "start_time": "2022-02-06T14:14:51.524302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class JigsawDataset(Dataset):\n",
    "    def __init__(self, df, data, tokenizer, max_length):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = df['text'].values\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        data = self.data[index]\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "                                text,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                max_length=self.max_len,\n",
    "                                padding='max_length'\n",
    "                            )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']     \n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'data': torch.tensor(data, dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:14:51.589488Z",
     "iopub.status.busy": "2022-02-06T14:14:51.588989Z",
     "iopub.status.idle": "2022-02-06T14:14:51.605749Z",
     "shell.execute_reply": "2022-02-06T14:14:51.605254Z",
     "shell.execute_reply.started": "2022-02-04T10:26:04.412058Z"
    },
    "papermill": {
     "duration": 0.040835,
     "end_time": "2022-02-06T14:14:51.605856",
     "exception": false,
     "start_time": "2022-02-06T14:14:51.565021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "OUT_DROPOUT = 0.3\n",
    "BERT_N_LAST_LAYER = 4\n",
    "BERT_HIDDEN_SIZE = 768\n",
    "\n",
    "BERT_MODEL_PATH = '../input/roberta-base'\n",
    "\n",
    "class JigsawModel(nn.Module):\n",
    "    def __init__(self, num_aux_targets, num_sentence_features):\n",
    "        super(JigsawModel, self).__init__()\n",
    "        self.bert_model = RobertaModel.from_pretrained(BERT_MODEL_PATH)\n",
    "        self.dropout = nn.Dropout(OUT_DROPOUT)\n",
    "        \n",
    "        self.linear_sentence1 = nn.Linear(num_sentence_features, num_sentence_features)\n",
    "        \n",
    "        n_hidden = BERT_HIDDEN_SIZE + num_sentence_features\n",
    "        self.linear1 = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        self.linear_out = nn.Linear(n_hidden, 1)\n",
    "        self.linear_aux_out = nn.Linear(n_hidden, num_aux_targets)\n",
    "        \n",
    "    def forward(self, ids, attention, sentence_features):\n",
    "        \n",
    "        bert_output = self.bert_model(ids, attention)[1]\n",
    "        \n",
    "        bert_output = self.dropout(bert_output)\n",
    "        \n",
    "        h_sentence = self.linear_sentence1(sentence_features)\n",
    "        \n",
    "        h_cat = torch.cat((bert_output, h_sentence), 1)\n",
    "        \n",
    "        h_conc_linear1  = F.relu(self.linear1(h_cat))\n",
    "        \n",
    "        hidden = h_cat + h_conc_linear1\n",
    "        \n",
    "        result = self.linear_out(hidden)\n",
    "        aux_result = self.linear_aux_out(hidden)\n",
    "        out = torch.cat([result, aux_result], 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:14:51.644655Z",
     "iopub.status.busy": "2022-02-06T14:14:51.643898Z",
     "iopub.status.idle": "2022-02-06T14:14:51.646235Z",
     "shell.execute_reply": "2022-02-06T14:14:51.645832Z",
     "shell.execute_reply.started": "2022-02-04T10:26:04.909112Z"
    },
    "papermill": {
     "duration": 0.023555,
     "end_time": "2022-02-06T14:14:51.646339",
     "exception": false,
     "start_time": "2022-02-06T14:14:51.622784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    \n",
    "    for step, data in bar:        \n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        data = data['data'].to(device)\n",
    "        outputs = model(ids, mask, data)\n",
    "        \n",
    "        all_preds += [outputs.detach().cpu().numpy()]\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:14:51.683433Z",
     "iopub.status.busy": "2022-02-06T14:14:51.682663Z",
     "iopub.status.idle": "2022-02-06T14:14:51.685004Z",
     "shell.execute_reply": "2022-02-06T14:14:51.684542Z",
     "shell.execute_reply.started": "2022-02-04T10:26:05.31905Z"
    },
    "papermill": {
     "duration": 0.023007,
     "end_time": "2022-02-06T14:14:51.685106",
     "exception": false,
     "start_time": "2022-02-06T14:14:51.662099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "def prepare_loaders():\n",
    "    sc = joblib.load(\n",
    "        '../input/jigsawrobertaunintended/scaler-seed0-fold0.joblib'\n",
    "    )\n",
    "    \n",
    "    data_test = sc.transform(sentence_df[SENTENCE_FEATURE_USED].values)\n",
    "    \n",
    "    test_dataset = JigsawDataset(\n",
    "        df, data_test, tokenizer=CONFIG['tokenizer'], max_length=CONFIG['max_length']\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:14:51.720120Z",
     "iopub.status.busy": "2022-02-06T14:14:51.719600Z",
     "iopub.status.idle": "2022-02-06T14:15:07.168827Z",
     "shell.execute_reply": "2022-02-06T14:15:07.168319Z",
     "shell.execute_reply.started": "2022-02-04T10:26:06.69797Z"
    },
    "papermill": {
     "duration": 15.468199,
     "end_time": "2022-02-06T14:15:07.168964",
     "exception": false,
     "start_time": "2022-02-06T14:14:51.700765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Create Dataloaders\n",
    "test_loader = prepare_loaders()\n",
    "\n",
    "model = JigsawModel(6, 15)\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        '../input/jigsawrobertaunintended/Loss-Fold-4_roberta_base_exp.bin'\n",
    "    )\n",
    ")\n",
    "model.to(CONFIG['device']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:15:07.206062Z",
     "iopub.status.busy": "2022-02-06T14:15:07.205421Z",
     "iopub.status.idle": "2022-02-06T14:15:47.730687Z",
     "shell.execute_reply": "2022-02-06T14:15:47.730201Z",
     "shell.execute_reply.started": "2022-02-04T10:26:30.220496Z"
    },
    "papermill": {
     "duration": 40.545605,
     "end_time": "2022-02-06T14:15:47.730818",
     "exception": false,
     "start_time": "2022-02-06T14:15:07.185213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [00:40<00:00, 11.70it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = valid_one_epoch(model, test_loader, CONFIG['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:15:47.885069Z",
     "iopub.status.busy": "2022-02-06T14:15:47.884288Z",
     "iopub.status.idle": "2022-02-06T14:15:47.888865Z",
     "shell.execute_reply": "2022-02-06T14:15:47.888418Z",
     "shell.execute_reply.started": "2022-02-04T10:28:13.313912Z"
    },
    "papermill": {
     "duration": 0.082032,
     "end_time": "2022-02-06T14:15:47.888982",
     "exception": false,
     "start_time": "2022-02-06T14:15:47.806950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_preds = np.concatenate(preds)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T14:15:48.047499Z",
     "iopub.status.busy": "2022-02-06T14:15:48.046981Z",
     "iopub.status.idle": "2022-02-06T14:15:48.079171Z",
     "shell.execute_reply": "2022-02-06T14:15:48.078750Z",
     "shell.execute_reply.started": "2022-02-04T10:28:15.229859Z"
    },
    "papermill": {
     "duration": 0.114307,
     "end_time": "2022-02-06T14:15:48.079280",
     "exception": false,
     "start_time": "2022-02-06T14:15:47.964973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>2503.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>5162.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id   score\n",
       "0      114890   643.0\n",
       "1      732895   302.0\n",
       "2     1139051  2503.0\n",
       "3     1434512   204.0\n",
       "4     2084821  5162.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['score'] = out_preds\n",
    "df = df.drop(columns=['text'])\n",
    "df['score'] = df['score'].rank(method='first')\n",
    "df[['comment_id', 'score']].to_csv('submission.csv', index=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 245.487047,
   "end_time": "2022-02-06T14:15:51.699363",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-06T14:11:46.212316",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
